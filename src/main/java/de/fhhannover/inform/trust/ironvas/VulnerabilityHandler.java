/*
 * Project: ironvas
 * Package: de.fhhannover.inform.trust.ironvas
 * File:    VulnerabilityHandler.java
 *
 * Copyright (C) 2011-2012 Hochschule Hannover
 * Ricklinger Stadtweg 118, 30459 Hannover, Germany 
 *
 * Licensed under the Apache License, Version 2.0 (the License);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an AS IS BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package de.fhhannover.inform.trust.ironvas;

import java.util.List;
import java.util.Set;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.logging.Logger;

import de.fhhannover.inform.trust.ifmapj.channel.SSRC;
import de.fhhannover.inform.trust.ifmapj.exception.IfmapErrorResult;
import de.fhhannover.inform.trust.ifmapj.exception.IfmapException;
import de.fhhannover.inform.trust.ifmapj.messages.PublishElement;
import de.fhhannover.inform.trust.ifmapj.messages.PublishRequest;
import de.fhhannover.inform.trust.ifmapj.messages.Requests;
import de.fhhannover.inform.trust.ironvas.converter.Converter;

/**
 * The <code>VulnerabilityHandler</code> is responsible for publishing and
 * managing vulnerabilities.
 * 
 * @author Ralf Steuerwald
 *
 */
public class VulnerabilityHandler implements Runnable {
	
	private static final Logger logger =
			Logger.getLogger(VulnerabilityHandler.class.getName());

	private LinkedBlockingQueue<Report> workQueue =
			new LinkedBlockingQueue<Report>();
	
	protected VulnerabilityCache cache = new VulnerabilityCache();

	private SSRC ssrc;
	private Converter converter;

	public VulnerabilityHandler(SSRC ifmap, Converter converter) {
		this.ssrc = ifmap;
		this.converter = converter;
	}

	/**
	 * Run the handler loop. The following steps are performed:
	 * <p>
	 * 1. Wait for new vulnerabilities in the queue.<br>
	 * 2. If new vulnerabilities arrive:<br>
	 *    2.1. Check the arrived set for new vulnerabilities, not known in the
	 *         cache.<br>
	 *    2.2. Check the cache for out-dated vulnerabilities.<br>
	 *    2.3. Remove the out-dated vulnerabilities from the cache.<br>
	 *    2.4. Add the new vulnerabilities to the cache.<br>
	 *    2.5. Send a publish request to the MAPS including update elements
	 *         for the new and delete elements for the out-dated vulnerabilities.
	 * 3. Start at 1. again.
	 */
	@Override
	public void run() {
		logger.info("starting " + this.getClass().getSimpleName());
		
		try {
			while (!Thread.currentThread().isInterrupted()) {
				Report lastReport = workQueue.take();
				onNewReport(lastReport);
			}
		} catch (InterruptedException e) {
			Thread.currentThread().interrupt();
			logger.info("got interrupt signal while waiting for new work, exiting ...");
		}
		finally{
			logger.info("shutdown complete.");
		}
	}
	
	public void onNewReport(Report report) {
		String taskId = report.taskId;
		List<Vulnerability> vulnerabilities = report.vulnerabilities;
		
		Set<Vulnerability> news = cache.indicateNew(taskId, vulnerabilities);
		Set<Vulnerability> outDated = cache.indicateOutDated(taskId, vulnerabilities);
		
		updateCache(taskId, news, outDated);
		
		if (news.size() > 0 || outDated.size() > 0) {
			logger.info(String.format("publishing %d updates, %d deletes for task %s",
					news.size(), outDated.size(), report.taskId));
		}
		
		publish(news, outDated);
	}
	
	public void updateCache(String taskId, Set<Vulnerability> news, Set<Vulnerability> outDated) {
		cache.removeFromTask(taskId, outDated);
		cache.addToTask(taskId, news);
	}
	
	public void publish(Set<Vulnerability> news, Set<Vulnerability> outDated) {
		PublishRequest request = Requests.createPublishReq();
		
		if (news.size() > 0) {
			List<PublishElement> update = converter.toUpdates(news);
			mergeInto(update, request);
		}
		if (outDated.size() > 0) {
			List<PublishElement> delete = converter.toDeletes(outDated);
			mergeInto(delete, request);
		}
		
		if (news.size() > 0 || outDated.size() > 0) {
			try {
				ssrc.publish(request);
				
				// TODO in case of an ifmap exception the current request should be saved and resend with the next one (or an  immediately retry)
			} catch (IfmapErrorResult e) {
				logger.warning("error while sending publish request " + e);
			} catch (IfmapException e) {
				logger.warning("error while sending publish request " + e);
			}
		}
		
	}

	/**
	 * Submit a list of vulnerabilities to this {@link VulnerabilityHandler}.
	 * 
	 * @param lastReport the {@link Report} containing the vulnerabilities
	 */
	public void submit(Report lastReport) {
		try {
			workQueue.put(lastReport);
		} catch (InterruptedException e) {
			logger.severe(
					"could not submit vulnerabilities to handler "
					+ e.getMessage());
		}
	}

	private <T extends PublishElement> void mergeInto(List<T> elements,
			PublishRequest request) {
		for (T t : elements) {
			request.addPublishElement(t);
		}
	}
	
}
